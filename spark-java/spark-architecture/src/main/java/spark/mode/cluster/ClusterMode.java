/*

To execute jobs, Spark breaks up the processing of RDD operations into tasks - each of which is operated on by an executor.

Prior to execution, Spark computes the closure.

 */
package spark.mode.cluster;

public class ClusterMode {
}
