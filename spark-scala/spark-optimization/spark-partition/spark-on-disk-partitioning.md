# on disk partitioning

Spark provides the partitionBy() operator, which can be used to partition the data and store it in different files while writing the output.


